# Scripts Directory

Production-ready scripts for the **Land Estimator** Document Mode data ingestion pipeline.

---

## ğŸ“Œ Purpose

This pipeline processes raw parcel shapefiles for St. Louis City and County and outputs:

- âœ… Lightweight **document.json** files for **hot search** (FlexSearch Document Mode)
- âœ… Regionally sharded **address indexes**, **parcel metadata**, and **geometry** files for **cold storage**
- âœ… Compressed `.json.gz` files to minimize storage costs for large intermediate data
- âœ… Uploads to **Vercel Blob Storage** (`/search/` and `/cdn/`) and **Firebase** backup

---

## ğŸ—‚ï¸ Directory Contract

| Folder                          | Purpose                                                          |
| ------------------------------- | ---------------------------------------------------------------- |
| `/src/data/`                    | Source shapefiles per region                                     |
| `/src/config/scripts/temp/raw/` | Raw intermediate files: address index, parcel metadata, geometry |
| `/src/config/scripts/temp/cdn/` | Compressed `.json.gz` files for cold storage                     |
| `/public/search/`               | Final `*-document.json` files for client-side search             |
| `/cdn/`                         | Long-term storage for compressed intermediate files              |

---

## âš™ï¸ Pipeline Steps

1ï¸âƒ£ **Process Regional Shapefiles**

- Uses `geopandas` to load shapefiles, CSV, and DBF files.
- Calculates parcel areas, property types, owners, and assessments.
- Extracts **WGS84** centroids for accurate map placement.

2ï¸âƒ£ **Create Intermediate Files**

- `*-address_index.json`: Basic ID/address/lat/lng per parcel.
- `*-parcel_metadata.json`: Full calculations, ownership, assessments.
- `*-parcel_geometry.json`: Simplified parcel shapes in GeoJSON format.

3ï¸âƒ£ **Compress for Cold Storage**

- Metadata and geometry files are compressed (`.json.gz`) to reduce storage costs.

4ï¸âƒ£ **Upload**

- Hot search files (`document.json` and `latest.json`) â†’ `/public/search/` (Vercel edge CDN).
- Compressed regionals (`.json.gz`) â†’ `/cdn/` (Vercel Blob) + Firebase for redundancy.

5ï¸âƒ£ **Cleanup**

- All temp files in `temp/` are removed after upload. Persistent intermediate files are kept under `/src/data/tmp/` for rebuilds.

---

## ğŸ“¦ Dependencies

**Python**

- `geopandas` â€” For shapefile processing and CRS transformations.
- `shapely` â€” Geometry operations.
- `pandas` â€” Data merging and cleaning.
- `dbfread` â€” DBF file reading for parcel attributes.
- `gzip` â€” Compressing large intermediate files.
- `subprocess` â€” Runs Node upload scripts for Vercel Blob and Firebase.

**Node.js**

- `upload_blob.js` â€” Handles uploads to Vercel Blob Storage using the official SDK.
- `upload_firebase.js` â€” Handles Firebase backup uploads.

---

## âœ… Why This Structure?

- Keeps **hot search data minimal** for fast edge delivery.
- Preserves **full parcel detail** in cold storage for advanced GIS or backup.
- Supports **regional sharding** and future scaling (e.g., IP-based lookup).
- Ensures **coordinate accuracy** by transforming all geometries to **WGS84**.
- Uses a **clear ephemeral model**: temp dirs are safe to delete; persistent data is always reproducible.

---

## ï¿½ Current Scripts

**Core Pipeline:**

- `ingest_shapes.py` â€” Main data ingestion pipeline (CRS fixes, document generation, manifest creation)
- `validate_geometries.py` â€” Geometry validation and CRS verification utility

**Upload Scripts:**

- `upload_blob.js` â€” Vercel Blob Storage upload
- `upload_blob.py` â€” Alternative Python upload script
- `upload_firebase.js` â€” Firebase backup upload

**Configuration:**

- `README.md` â€” This documentation
- `requirements.txt` â€” Python dependencies

---

## ï¿½ğŸš€ Usage

```bash
# Run the full Document Mode pipeline
python3 ingest_shapes.py --dataset-size=small --version=mytag

# Dataset sizes:
# --dataset-size=small   # 5,000 parcels (testing)
# --dataset-size=medium  # 25,000 parcels (development)
# --dataset-size=large   # Full dataset (production)

# Validate geometries (optional)
python3 validate_geometries.py

# Upload scripts must be present:
# - upload_blob.js
# - upload_firebase.js
```

---

**Designed for robust regional search & estimation at scale.**
